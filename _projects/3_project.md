---
layout: page
title: Parameter-Efficient Fine-Tuning for Vision-Language Models
description: Enhancing CLIP with Mixture of Experts and PEFT methods (prompt tuning, adapters) for multi-modal scenarios.
img: assets/img/1.jpg
importance: 3
category: work
related_publications: false
---

This project explores the application of **Parameter-Efficient Fine-Tuning (PEFT)** methods to Vision-Language models, specifically focusing on **CLIP** (Contrastive Language-Image Pre-training).

The study introduces a comprehensive evaluation framework to assess the performance of PEFT methods, such as prompt tuning and adapters, across diverse backbones and datasets. The goal is to enhance CLIP's adaptability in complex, multi-modal scenarios by leveraging **Mixture of Experts (MOE)** and other PEFT techniques.

**Status:** In progress.
